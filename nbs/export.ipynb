{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-02 16:30:26.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mInitializing Predictor with device=auto\u001b[0m\n",
      "\u001b[32m2025-04-02 16:30:26.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.predictor\u001b[0m:\u001b[36m_setup_device\u001b[0m:\u001b[36m168\u001b[0m - \u001b[1mAuto-selected device: cuda\u001b[0m\n",
      "\u001b[32m2025-04-02 16:30:26.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.predictor\u001b[0m:\u001b[36m_download_checkpoint\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mDownloading checkpoint for model deim_hgnetv2_x...\u001b[0m\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1dPtbgtGgq1Oa7k_LgH1GXPelg1IVeu0j\n",
      "From (redirected): https://drive.google.com/uc?id=1dPtbgtGgq1Oa7k_LgH1GXPelg1IVeu0j&confirm=t&uuid=b8b8be39-c2e9-4de7-bd7e-4bd5d14ba721\n",
      "To: /home/dnth/Desktop/DEIMKit/nbs/checkpoints/deim_hgnetv2_x.pth\n",
      "100%|██████████| 252M/252M [00:56<00:00, 4.50MB/s] \n",
      "\u001b[32m2025-04-02 16:31:27.994\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdeimkit.predictor\u001b[0m:\u001b[36m_download_checkpoint\u001b[0m:\u001b[36m200\u001b[0m - \u001b[32m\u001b[1mDownloaded checkpoint to checkpoints/deim_hgnetv2_x.pth\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:28.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.predictor\u001b[0m:\u001b[36m_setup_model_config\u001b[0m:\u001b[36m232\u001b[0m - \u001b[1mLoading configuration from model name: deim_hgnetv2_x\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:28.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.predictor\u001b[0m:\u001b[36m_setup_model_config\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mUpdating model configuration for 80 classes\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:28.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.predictor\u001b[0m:\u001b[36m_load_model_weights\u001b[0m:\u001b[36m253\u001b[0m - \u001b[1mSuccessfully loaded checkpoint weights\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:28.976\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdeimkit.predictor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m155\u001b[0m - \u001b[32m\u001b[1mPredictor initialization complete\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from deimkit import list_models, load_model\n",
    "\n",
    "coco_classes = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "    'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork',\n",
    "    'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "model = load_model(\"deim_hgnetv2_x\", class_names=coco_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task: detection\n",
       "num_workers: 0\n",
       "batch_size: None\n",
       "resume: None\n",
       "tuning: None\n",
       "epoches: 58\n",
       "last_epoch: -1\n",
       "lrsheduler: flatcosine\n",
       "lr_gamma: 0.5\n",
       "no_aug_epoch: 8\n",
       "warmup_iter: 2000\n",
       "flat_epoch: 29\n",
       "use_amp: True\n",
       "use_ema: True\n",
       "ema_decay: 0.9999\n",
       "ema_warmups: 2000\n",
       "sync_bn: True\n",
       "clip_max_norm: 0.1\n",
       "find_unused_parameters: False\n",
       "seed: None\n",
       "print_freq: 100\n",
       "checkpoint_freq: 4\n",
       "output_dir: ./outputs/deim_hgnetv2_x_coco\n",
       "summary_dir: None\n",
       "device: \n",
       "yaml_cfg: {'task': 'detection', 'evaluator': {'type': 'CocoEvaluator', 'iou_types': ['bbox']}, 'num_classes': 80, 'remap_mscoco_category': True, 'train_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/datassd/COCO/train2017/', 'ann_file': '/datassd/COCO/annotations/instances_train2017.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'Mosaic', 'output_size': 640, 'rotation_range': 10, 'translation_range': [0.1, 0.1], 'scaling_range': [0.5, 1.5], 'probability': 1.0, 'fill_value': 0, 'use_cache': False, 'max_cached_images': 50, 'random_pop': True}, {'type': 'RandomPhotometricDistort', 'p': 0.5}, {'type': 'RandomZoomOut', 'fill': 0}, {'type': 'RandomIoUCrop', 'p': 0.8}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'RandomHorizontalFlip'}, {'type': 'Resize', 'size': (640, 640)}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}, {'type': 'ConvertBoxes', 'fmt': 'cxcywh', 'normalize': True}], 'policy': {'name': 'stop_epoch', 'epoch': [4, 29, 50], 'ops': ['Mosaic', 'RandomPhotometricDistort', 'RandomZoomOut', 'RandomIoUCrop']}, 'mosaic_prob': 0.5}}, 'shuffle': True, 'num_workers': 4, 'drop_last': True, 'collate_fn': {'type': 'BatchImageCollateFunction', 'base_size': 640, 'base_size_repeat': 3, 'stop_epoch': 50, 'ema_restart_decay': 0.9998, 'mixup_prob': 0.5, 'mixup_epochs': [4, 29]}, 'total_batch_size': 32}, 'val_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/datassd/COCO/val2017/', 'ann_file': '/datassd/COCO/annotations/instances_val2017.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'Resize', 'size': (640, 640)}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}]}}, 'shuffle': False, 'num_workers': 4, 'drop_last': False, 'collate_fn': {'type': 'BatchImageCollateFunction'}, 'total_batch_size': 64}, 'print_freq': 100, 'output_dir': './outputs/deim_hgnetv2_x_coco', 'checkpoint_freq': 4, 'sync_bn': True, 'find_unused_parameters': False, 'use_amp': True, 'scaler': {'type': 'GradScaler', 'enabled': True}, 'use_ema': True, 'ema': {'type': 'ModelEMA', 'decay': 0.9999, 'warmups': 1000, 'start': 0}, 'epoches': 58, 'clip_max_norm': 0.1, 'optimizer': {'type': 'AdamW', 'params': [{'params': '^(?=.*backbone)(?!.*norm|bn).*$', 'lr': 5e-06}, {'params': '^(?=.*(?:encoder|decoder))(?=.*(?:norm|bn)).*$', 'weight_decay': 0.0}], 'lr': 0.0005, 'betas': [0.9, 0.999], 'weight_decay': 0.000125}, 'lr_scheduler': {'type': 'MultiStepLR', 'milestones': [500], 'gamma': 0.1}, 'lr_warmup_scheduler': {'type': 'LinearWarmup', 'warmup_duration': 500}, 'model': 'DEIM', 'criterion': 'DEIMCriterion', 'postprocessor': 'PostProcessor', 'use_focal_loss': True, 'eval_spatial_size': (640, 640), 'DEIM': {'backbone': 'HGNetv2', 'encoder': 'HybridEncoder', 'decoder': 'DFINETransformer'}, 'lrsheduler': 'flatcosine', 'lr_gamma': 0.5, 'warmup_iter': 2000, 'flat_epoch': 29, 'no_aug_epoch': 8, 'HGNetv2': {'pretrained': False, 'local_model_dir': '../RT-DETR-main/D-FINE/weight/hgnetv2/', 'name': 'B5', 'return_idx': [1, 2, 3], 'freeze_stem_only': True, 'freeze_at': -1, 'freeze_norm': False}, 'HybridEncoder': {'in_channels': [512, 1024, 2048], 'feat_strides': [8, 16, 32], 'hidden_dim': 384, 'use_encoder_idx': [2], 'num_encoder_layers': 1, 'nhead': 8, 'dim_feedforward': 2048, 'dropout': 0.0, 'enc_act': 'gelu', 'expansion': 1.0, 'depth_mult': 1, 'act': 'silu'}, 'DFINETransformer': {'feat_channels': [384, 384, 384], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'num_levels': 3, 'num_layers': 6, 'eval_idx': -1, 'num_queries': 300, 'num_denoising': 100, 'label_noise_ratio': 0.5, 'box_noise_scale': 1.0, 'reg_max': 32, 'reg_scale': 8, 'layer_scale': 1, 'num_points': [3, 6, 3], 'cross_attn_method': 'default', 'query_select_method': 'default', 'activation': 'silu', 'mlp_act': 'silu'}, 'PostProcessor': {'num_top_queries': 300}, 'DEIMCriterion': {'weight_dict': {'loss_vfl': 1, 'loss_bbox': 5, 'loss_giou': 2, 'loss_fgl': 0.15, 'loss_ddf': 1.5, 'loss_mal': 1}, 'losses': ['mal', 'boxes', 'local'], 'alpha': 0.75, 'gamma': 1.5, 'reg_max': 32, 'matcher': {'type': 'HungarianMatcher', 'weight_dict': {'cost_class': 2, 'cost_bbox': 5, 'cost_giou': 2}, 'alpha': 0.25, 'gamma': 2.0}}, '__include__': ['./dfine_hgnetv2_x_coco.yml', '../base/deim.yml']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cfg.save(\"./checkpoints/deim_hgnetv2_x.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-02 16:31:29.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36mto_onnx\u001b[0m:\u001b[36m123\u001b[0m - \u001b[1mUsing device: cpu\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:29.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36mto_onnx\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mLoading checkpoint from ./checkpoints/deim_hgnetv2_x.pth\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:29.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36mto_onnx\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mEMA weights not found, using regular model weights\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:29.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36mto_onnx\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mInput shape not provided, getting size from config\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:29.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36mto_onnx\u001b[0m:\u001b[36m188\u001b[0m - \u001b[1mUsing target shape from config: (1, 3, 640, 640)\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:29.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mInitialized PreprocessingModule with target size: (640, 640)\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:29.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36mto_onnx\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mIncluding preprocessing steps in the ONNX model.\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:29.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36mto_onnx\u001b[0m:\u001b[36m260\u001b[0m - \u001b[1mUsing input names: ['input_bgr', 'orig_target_sizes']\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:29.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36mto_onnx\u001b[0m:\u001b[36m261\u001b[0m - \u001b[1mUsing output names: ['labels', 'boxes', 'scores']\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:29.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36mto_onnx\u001b[0m:\u001b[36m262\u001b[0m - \u001b[1mUsing dynamic axes: {'input_bgr': {0: 'N', 2: 'H', 3: 'W'}, 'orig_target_sizes': {0: 'N'}, 'labels': {0: 'N'}, 'boxes': {0: 'N'}, 'scores': {0: 'N'}}\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:29.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36mto_onnx\u001b[0m:\u001b[36m263\u001b[0m - \u001b[1mExporting model to ONNX: ./checkpoints/deim_hgnetv2_x.onnx\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:29.662\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36mforward\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mPreprocessing: Resized shape: torch.Size([1, 3, 640, 640])\u001b[0m\n",
      "/home/dnth/Desktop/DEIMKit/src/deimkit/exporter.py:58: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x.shape[1] != 3:\n",
      "\u001b[32m2025-04-02 16:31:29.666\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36mforward\u001b[0m:\u001b[36m62\u001b[0m - \u001b[34m\u001b[1mPreprocessing: Swapped BGR to RGB\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:29.667\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36mforward\u001b[0m:\u001b[36m67\u001b[0m - \u001b[34m\u001b[1mPreprocessing: Normalized pixel values to [0, 1]\u001b[0m\n",
      "/home/dnth/Desktop/DEIMKit/src/deimkit/engine/deim/dfine_decoder.py:646: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if memory.shape[0] > 1:\n",
      "/home/dnth/Desktop/DEIMKit/src/deimkit/engine/deim/dfine_decoder.py:129: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if reference_points.shape[-1] == 2:\n",
      "/home/dnth/Desktop/DEIMKit/src/deimkit/engine/deim/dfine_decoder.py:133: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  elif reference_points.shape[-1] == 4:\n",
      "/home/dnth/Desktop/DEIMKit/.pixi/envs/cuda/lib/python3.11/site-packages/torch/onnx/_internal/jit_utils.py:308: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:178.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/home/dnth/Desktop/DEIMKit/.pixi/envs/cuda/lib/python3.11/site-packages/torch/onnx/utils.py:657: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:178.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/home/dnth/Desktop/DEIMKit/.pixi/envs/cuda/lib/python3.11/site-packages/torch/onnx/utils.py:1127: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:178.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "\u001b[32m2025-04-02 16:31:34.042\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36mto_onnx\u001b[0m:\u001b[36m285\u001b[0m - \u001b[32m\u001b[1mONNX export completed successfully: ./checkpoints/deim_hgnetv2_x.onnx\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:34.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36mto_onnx\u001b[0m:\u001b[36m296\u001b[0m - \u001b[1mSimplifying ONNX model with input shapes: {'input_bgr': torch.Size([1, 3, 640, 640]), 'orig_target_sizes': torch.Size([1, 2])}\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:34.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36m_simplify_onnx_model\u001b[0m:\u001b[36m401\u001b[0m - \u001b[1mSimplifying ONNX model: ./checkpoints/deim_hgnetv2_x.onnx -> ./checkpoints/deim_hgnetv2_x.onnx\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:49.184\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36m_simplify_onnx_model\u001b[0m:\u001b[36m411\u001b[0m - \u001b[32m\u001b[1mONNX model simplification successful: ./checkpoints/deim_hgnetv2_x.onnx\u001b[0m\n",
      "\u001b[32m2025-04-02 16:31:49.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeimkit.exporter\u001b[0m:\u001b[36m_check_onnx_model\u001b[0m:\u001b[36m368\u001b[0m - \u001b[1mONNX model validation successful: ./checkpoints/deim_hgnetv2_x.onnx\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from deimkit.exporter import Exporter\n",
    "from deimkit.config import Config\n",
    "\n",
    "config = Config(\"./checkpoints/deim_hgnetv2_x.yml\")\n",
    "exporter = Exporter(config)\n",
    "\n",
    "output_path = exporter.to_onnx(\n",
    "    checkpoint_path=\"./checkpoints/deim_hgnetv2_x.pth\",\n",
    "    output_path=\"./checkpoints/deim_hgnetv2_x.onnx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
